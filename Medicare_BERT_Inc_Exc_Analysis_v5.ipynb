{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wXIft7gwDVM3",
    "outputId": "8d58e721-b690-4641-9656-1d51bc1da17d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
      "\r",
      "\u001b[K     |▏                               | 10kB 22.9MB/s eta 0:00:01\r",
      "\u001b[K     |▎                               | 20kB 30.2MB/s eta 0:00:01\r",
      "\u001b[K     |▌                               | 30kB 22.1MB/s eta 0:00:01\r",
      "\u001b[K     |▋                               | 40kB 20.5MB/s eta 0:00:01\r",
      "\u001b[K     |▉                               | 51kB 22.5MB/s eta 0:00:01\r",
      "\u001b[K     |█                               | 61kB 16.4MB/s eta 0:00:01\r",
      "\u001b[K     |█▏                              | 71kB 17.2MB/s eta 0:00:01\r",
      "\u001b[K     |█▎                              | 81kB 17.8MB/s eta 0:00:01\r",
      "\u001b[K     |█▍                              | 92kB 16.8MB/s eta 0:00:01\r",
      "\u001b[K     |█▋                              | 102kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█▊                              | 112kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 122kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 133kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██▎                             | 143kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██▍                             | 153kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██▌                             | 163kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██▊                             | 174kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██▉                             | 184kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 194kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███▏                            | 204kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███▍                            | 215kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███▌                            | 225kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███▋                            | 235kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███▉                            | 245kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 256kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████▏                           | 266kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████▎                           | 276kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████▌                           | 286kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████▋                           | 296kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████▊                           | 307kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 317kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 327kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████▎                          | 337kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████▍                          | 348kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████▋                          | 358kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████▊                          | 368kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████▉                          | 378kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 389kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████▏                         | 399kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████▍                         | 409kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████▌                         | 419kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████▊                         | 430kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████▉                         | 440kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 450kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████▏                        | 460kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████▎                        | 471kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████▌                        | 481kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 491kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████▉                        | 501kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 512kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 522kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████▎                       | 532kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████▍                       | 542kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████▋                       | 552kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████▊                       | 563kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 573kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 583kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▎                      | 593kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▍                      | 604kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▌                      | 614kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▊                      | 624kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▉                      | 634kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 645kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▏                     | 655kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▍                     | 665kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▌                     | 675kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▋                     | 686kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▉                     | 696kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 706kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▏                    | 716kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▎                    | 727kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▌                    | 737kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▋                    | 747kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▊                    | 757kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 768kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 778kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▎                   | 788kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▍                   | 798kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▋                   | 808kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▊                   | 819kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▉                   | 829kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 839kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▏                  | 849kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▍                  | 860kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▌                  | 870kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▊                  | 880kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▉                  | 890kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 901kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▏                 | 911kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▎                 | 921kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▌                 | 931kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▋                 | 942kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▉                 | 952kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 962kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 972kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▎                | 983kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▍                | 993kB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 1.0MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▊                | 1.0MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 1.0MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 1.0MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▏               | 1.0MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▍               | 1.1MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▌               | 1.1MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▊               | 1.1MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▉               | 1.1MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 1.1MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▏              | 1.1MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▍              | 1.1MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▌              | 1.1MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▋              | 1.1MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▉              | 1.1MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 1.2MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▏             | 1.2MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▎             | 1.2MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▌             | 1.2MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▋             | 1.2MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▊             | 1.2MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 1.2MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 1.2MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▎            | 1.2MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▍            | 1.2MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▋            | 1.3MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▊            | 1.3MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▉            | 1.3MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 1.3MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▏           | 1.3MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▍           | 1.3MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▌           | 1.3MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▊           | 1.3MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▉           | 1.3MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 1.4MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▏          | 1.4MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▎          | 1.4MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▌          | 1.4MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▋          | 1.4MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▉          | 1.4MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 1.4MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 1.4MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▎         | 1.4MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▍         | 1.4MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▋         | 1.5MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▊         | 1.5MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 1.5MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 1.5MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▏        | 1.5MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▍        | 1.5MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▌        | 1.5MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▊        | 1.5MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▉        | 1.5MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 1.5MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▏       | 1.6MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 1.6MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▌       | 1.6MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▋       | 1.6MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▉       | 1.6MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 1.6MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▏      | 1.6MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▎      | 1.6MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▍      | 1.6MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▋      | 1.6MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▊      | 1.7MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 1.7MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 1.7MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▎     | 1.7MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▍     | 1.7MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▋     | 1.7MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▊     | 1.7MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▉     | 1.7MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 1.7MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▏    | 1.8MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▍    | 1.8MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▌    | 1.8MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▊    | 1.8MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▉    | 1.8MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 1.8MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▏   | 1.8MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▎   | 1.8MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▌   | 1.8MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▋   | 1.8MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▉   | 1.9MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 1.9MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 1.9MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▎  | 1.9MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▍  | 1.9MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▋  | 1.9MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▊  | 1.9MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 1.9MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 1.9MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▏ | 1.9MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▍ | 2.0MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▌ | 2.0MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▊ | 2.0MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▉ | 2.0MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 2.0MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▏| 2.0MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▎| 2.0MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▌| 2.0MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▋| 2.0MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▉| 2.0MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 2.1MB 16.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 2.1MB 16.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3MB 52.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
      "\u001b[K     |████████████████████████████████| 901kB 40.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Installing collected packages: tokenizers, sacremoses, transformers\n",
      "Successfully installed sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "G1XxZdNnA_mg"
   },
   "outputs": [],
   "source": [
    " CUDA_LAUNCH_BLOCKING=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_we_dW519Opu",
    "outputId": "bdcba0d1-319f-4218-b843-81a26c3ff17d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seqeval\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
      "\r",
      "\u001b[K     |███████▌                        | 10kB 24.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 20kB 31.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▌         | 30kB 20.9MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 40kB 24.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 51kB 7.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.19.5)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (0.22.2.post1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\n",
      "Building wheels for collected packages: seqeval\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for seqeval: filename=seqeval-1.2.2-cp37-none-any.whl size=16172 sha256=5280c4f2bc5601559ecda7a09d32809e8de76ae8ce960dfa6a550d7abc35169f\n",
      "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
      "Successfully built seqeval\n",
      "Installing collected packages: seqeval\n",
      "Successfully installed seqeval-1.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lwSZMX_uCdS2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from seqeval.metrics import f1_score\n",
    "from seqeval.metrics import classification_report,accuracy_score,f1_score\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "bpocsdFgCdS-"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm,trange\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertConfig\n",
    "from transformers import BertForTokenClassification, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "MgX2s29aCdS_"
   },
   "outputs": [],
   "source": [
    "#!pip install pandas==0.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w9JIHXrjCdTA",
    "outputId": "de04236d-9686-481f-eeb6-63cd9534ed46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras                         2.4.3         \n",
      "Keras-Preprocessing           1.1.2         \n",
      "torch                         1.8.1+cu101   \n",
      "torchsummary                  1.5.1         \n",
      "torchtext                     0.9.1         \n",
      "torchvision                   0.9.1+cu101   \n",
      "transformers                  4.5.1         \n"
     ]
    }
   ],
   "source": [
    "# Check library version\n",
    "!pip list | grep -E 'transformers|torch|Keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "2TxDH0TuCdTB"
   },
   "outputs": [],
   "source": [
    "#df= pd.read_csv('medicare_BOI_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "uLl5i1fyCdTB"
   },
   "outputs": [],
   "source": [
    "# Fillna method can make same sentence with same sentence name\n",
    "#df_data = pd.read_csv('train_dataset_BOI_new1.csv',sep=\",\",encoding=\"latin1\").fillna(method='ffill')\n",
    "#df_data = pd.read_csv('sample_data/sample_input_dataset_bot.csv',sep=\",\",encoding=\"latin1\").fillna(method='ffill')\n",
    "df_data = pd.read_csv('sample_data/medicare_train_dataset_BOI_input_manual_v3.csv',sep=\",\",encoding=\"latin1\").fillna(method='ffill')\n",
    "#df_data = pd.read_csv('medicare_train_dataset_BOI_input.csv',sep=\",\",encoding=\"latin1\").fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fkz5fdVDCdTC",
    "outputId": "ce5711ed-47e2-4b09-980d-13f17bb89b1a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sentence #', 'pattern', 'benefit_type', 'requirement_text', 'word',\n",
       "       'POS', 'tags'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 639
    },
    "id": "aUHjt7M0CdTC",
    "outputId": "d44ffd86-a1ae-46cf-ff22-3c38324ff736"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence #</th>\n",
       "      <th>pattern</th>\n",
       "      <th>benefit_type</th>\n",
       "      <th>requirement_text</th>\n",
       "      <th>word</th>\n",
       "      <th>POS</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sentence 1</td>\n",
       "      <td>Includes programs such as group exercise, adul...</td>\n",
       "      <td>ADCS</td>\n",
       "      <td>Adult Day Care Services</td>\n",
       "      <td>Includes</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sentence 1</td>\n",
       "      <td>Includes programs such as group exercise, adul...</td>\n",
       "      <td>ADCS</td>\n",
       "      <td>Adult Day Care Services</td>\n",
       "      <td>programs</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sentence 1</td>\n",
       "      <td>Includes programs such as group exercise, adul...</td>\n",
       "      <td>ADCS</td>\n",
       "      <td>Adult Day Care Services</td>\n",
       "      <td>such</td>\n",
       "      <td>JJ</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sentence 1</td>\n",
       "      <td>Includes programs such as group exercise, adul...</td>\n",
       "      <td>ADCS</td>\n",
       "      <td>Adult Day Care Services</td>\n",
       "      <td>as</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sentence 1</td>\n",
       "      <td>Includes programs such as group exercise, adul...</td>\n",
       "      <td>ADCS</td>\n",
       "      <td>Adult Day Care Services</td>\n",
       "      <td>group</td>\n",
       "      <td>NN</td>\n",
       "      <td>B_INCLUSION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence 1</td>\n",
       "      <td>Includes programs such as group exercise, adul...</td>\n",
       "      <td>ADCS</td>\n",
       "      <td>Adult Day Care Services</td>\n",
       "      <td>exercise</td>\n",
       "      <td>NN</td>\n",
       "      <td>I_INCLUSION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sentence 1</td>\n",
       "      <td>Includes programs such as group exercise, adul...</td>\n",
       "      <td>ADCS</td>\n",
       "      <td>Adult Day Care Services</td>\n",
       "      <td>adult</td>\n",
       "      <td>NN</td>\n",
       "      <td>B_INCLUSION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sentence 1</td>\n",
       "      <td>Includes programs such as group exercise, adul...</td>\n",
       "      <td>ADCS</td>\n",
       "      <td>Adult Day Care Services</td>\n",
       "      <td>education</td>\n",
       "      <td>NN</td>\n",
       "      <td>I_INCLUSION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence 1</td>\n",
       "      <td>Includes programs such as group exercise, adul...</td>\n",
       "      <td>ADCS</td>\n",
       "      <td>Adult Day Care Services</td>\n",
       "      <td>classes</td>\n",
       "      <td>NNS</td>\n",
       "      <td>I_INCLUSION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sentence 1</td>\n",
       "      <td>Includes programs such as group exercise, adul...</td>\n",
       "      <td>ADCS</td>\n",
       "      <td>Adult Day Care Services</td>\n",
       "      <td>recreation</td>\n",
       "      <td>NN</td>\n",
       "      <td>U_INCLUSION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sentence 1</td>\n",
       "      <td>Includes programs such as group exercise, adul...</td>\n",
       "      <td>ADCS</td>\n",
       "      <td>Adult Day Care Services</td>\n",
       "      <td>nutritious</td>\n",
       "      <td>JJ</td>\n",
       "      <td>B_INCLUSION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sentence 1</td>\n",
       "      <td>Includes programs such as group exercise, adul...</td>\n",
       "      <td>ADCS</td>\n",
       "      <td>Adult Day Care Services</td>\n",
       "      <td>meals</td>\n",
       "      <td>NNS</td>\n",
       "      <td>I_INCLUSION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sentence 1</td>\n",
       "      <td>Includes programs such as group exercise, adul...</td>\n",
       "      <td>ADCS</td>\n",
       "      <td>Adult Day Care Services</td>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sentence 1</td>\n",
       "      <td>Includes programs such as group exercise, adul...</td>\n",
       "      <td>ADCS</td>\n",
       "      <td>Adult Day Care Services</td>\n",
       "      <td>social</td>\n",
       "      <td>JJ</td>\n",
       "      <td>B_INCLUSION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sentence 1</td>\n",
       "      <td>Includes programs such as group exercise, adul...</td>\n",
       "      <td>ADCS</td>\n",
       "      <td>Adult Day Care Services</td>\n",
       "      <td>work</td>\n",
       "      <td>NN</td>\n",
       "      <td>I_INCLUSION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sentence 1</td>\n",
       "      <td>Includes programs such as group exercise, adul...</td>\n",
       "      <td>ADCS</td>\n",
       "      <td>Adult Day Care Services</td>\n",
       "      <td>services</td>\n",
       "      <td>NNS</td>\n",
       "      <td>I_INCLUSION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sentence 2</td>\n",
       "      <td>1) Coverage is available for up to one (1) vis...</td>\n",
       "      <td>ADCS</td>\n",
       "      <td>Adult Day Care Services</td>\n",
       "      <td>Coverage</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sentence 2</td>\n",
       "      <td>1) Coverage is available for up to one (1) vis...</td>\n",
       "      <td>ADCS</td>\n",
       "      <td>Adult Day Care Services</td>\n",
       "      <td>is</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sentence 2</td>\n",
       "      <td>1) Coverage is available for up to one (1) vis...</td>\n",
       "      <td>ADCS</td>\n",
       "      <td>Adult Day Care Services</td>\n",
       "      <td>available</td>\n",
       "      <td>JJ</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sentence 2</td>\n",
       "      <td>1) Coverage is available for up to one (1) vis...</td>\n",
       "      <td>ADCS</td>\n",
       "      <td>Adult Day Care Services</td>\n",
       "      <td>for</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentence #  ...         tags\n",
       "0   sentence 1  ...            O\n",
       "1   sentence 1  ...            O\n",
       "2   sentence 1  ...            O\n",
       "3   sentence 1  ...            O\n",
       "4   sentence 1  ...  B_INCLUSION\n",
       "5   sentence 1  ...  I_INCLUSION\n",
       "6   sentence 1  ...  B_INCLUSION\n",
       "7   sentence 1  ...  I_INCLUSION\n",
       "8   sentence 1  ...  I_INCLUSION\n",
       "9   sentence 1  ...  U_INCLUSION\n",
       "10  sentence 1  ...  B_INCLUSION\n",
       "11  sentence 1  ...  I_INCLUSION\n",
       "12  sentence 1  ...            O\n",
       "13  sentence 1  ...  B_INCLUSION\n",
       "14  sentence 1  ...  I_INCLUSION\n",
       "15  sentence 1  ...  I_INCLUSION\n",
       "16  sentence 2  ...            O\n",
       "17  sentence 2  ...            O\n",
       "18  sentence 2  ...            O\n",
       "19  sentence 2  ...            O\n",
       "\n",
       "[20 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-w4KL8CZCdTD",
    "outputId": "f6d21166-1c4b-46c9-b822-73c082f7b354"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NNS', 'JJ', 'IN', 'NN', 'CC', 'VBZ', 'TO', 'VB', 'PRP', 'MD',\n",
       "       'RB', 'DT', 'VBN', 'WDT', 'VBG', 'NNP', 'RBR', 'VBP', ':', 'NNPS',\n",
       "       'CD', 'VBD', 'EX', 'PRP$', 'JJS', 'SYM', 'WRB', 'WP', 'JJR', 'RP',\n",
       "       'WP$', 'RBS'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.POS.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EWw7DC6ECdTD",
    "outputId": "9264fd41-aaf7-4229-e6fb-c5cc9666d41e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['O', 'B_INCLUSION', 'I_INCLUSION', 'U_INCLUSION', 'B_EXCLUSION',\n",
       "       'I_EXCLUSION', 'U_EXCLUSION', 'i_EXCLUSION'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.tags.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F24tAd-fCdTE",
    "outputId": "2366cff7-076a-40cf-ae81-8a5de3ab90b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 1677, 32, 8)"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyse summary of data\n",
    "df_data['sentence #'].nunique(), df_data.word.nunique(), df_data.POS.nunique(), df_data.tags.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ROfaRORfCdTE",
    "outputId": "7743e431-b2c3-4984-c74a-254a883717f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O              4874\n",
       "I_INCLUSION     869\n",
       "B_INCLUSION     391\n",
       "I_EXCLUSION     238\n",
       "U_INCLUSION     121\n",
       "B_EXCLUSION      92\n",
       "U_EXCLUSION      31\n",
       "i_EXCLUSION       6\n",
       "Name: tags, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyse the Tag distribution\n",
    "df_data.tags.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "uetQdWH-CdTE"
   },
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w,b,r, p, t) for w,b,r, p, t in zip(s['word'].values.tolist(),\n",
    "                                                           s['benefit_type'].values.tolist(),\n",
    "                                                           s['requirement_text'].values.tolist(),\n",
    "                                                           s['POS'].values.tolist(), \n",
    "                                                           s['tags'].values.tolist())]\n",
    "        self.grouped = self.data.groupby('sentence #').apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "        \n",
    "    def get_next(self):\n",
    "        try: \n",
    "            s = self.grouped['sentence: {}'.format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s \n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "kjCCM-xTCdTF"
   },
   "outputs": [],
   "source": [
    "# Get full document data struce\n",
    "getter = SentenceGetter(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "saAdHKVXCdTF",
    "outputId": "c5986df6-e7f5-4718-8925-86eb91f8da42"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Includes',\n",
       " 'programs',\n",
       " 'such',\n",
       " 'as',\n",
       " 'group',\n",
       " 'exercise',\n",
       " 'adult',\n",
       " 'education',\n",
       " 'classes',\n",
       " 'recreation',\n",
       " 'nutritious',\n",
       " 'meals',\n",
       " 'and',\n",
       " 'social',\n",
       " 'work',\n",
       " 'services']"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get sentence data\n",
    "sentences = [[s[0] for s in sent] for sent in getter.sentences]\n",
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fx84m44aCdTG",
    "outputId": "e06cf756-afe7-4e01-c920-3beca85af9f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NNS', 'NNS', 'JJ', 'IN', 'NN', 'NN', 'NN', 'NN', 'NNS', 'NN', 'JJ', 'NNS', 'CC', 'JJ', 'NN', 'NNS']\n"
     ]
    }
   ],
   "source": [
    "# Get pos data\n",
    "poses = [[s[3] for s in sent] for sent in getter.sentences]\n",
    "print(poses[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z5fExMBVCdTG",
    "outputId": "da446b89-e44d-402f-df3f-8db9ae85392f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'B_INCLUSION', 'I_INCLUSION', 'B_INCLUSION', 'I_INCLUSION', 'I_INCLUSION', 'U_INCLUSION', 'B_INCLUSION', 'I_INCLUSION', 'O', 'B_INCLUSION', 'I_INCLUSION', 'I_INCLUSION']\n"
     ]
    }
   ],
   "source": [
    "# Get tag labels data\n",
    "labels = [[s[4] for s in sent] for sent in getter.sentences]\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "y1lcZESbCdTH"
   },
   "outputs": [],
   "source": [
    "tags_vals = list(set(df_data[\"tags\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "96VsDOXYCdTH"
   },
   "outputs": [],
   "source": [
    "# Add X  label for word piece support\n",
    "# Add [CLS] and [SEP] as BERT need\n",
    "tags_vals.append('X')\n",
    "tags_vals.append('[CLS]')\n",
    "tags_vals.append('[SEP]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "rIPqk8GoCdTH"
   },
   "outputs": [],
   "source": [
    "tags_vals = set(tags_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Svwznq4BCdTI",
    "outputId": "5eee2fec-81a3-4d8b-898b-9b40f99ce0d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B_EXCLUSION',\n",
       " 'B_INCLUSION',\n",
       " 'I_EXCLUSION',\n",
       " 'I_INCLUSION',\n",
       " 'O',\n",
       " 'U_EXCLUSION',\n",
       " 'U_INCLUSION',\n",
       " 'X',\n",
       " '[CLS]',\n",
       " '[SEP]',\n",
       " 'i_EXCLUSION'}"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "OyS0R4IvCdTI"
   },
   "outputs": [],
   "source": [
    "# Set a dict for mapping id to tag name\n",
    "#tag2idx = {t: i for i, t in enumerate(tags_vals)}\n",
    "# Recommend to set it by manual define, good for reusing\n",
    "# tag2idx={'B_EXCLUSION': 14,\n",
    "#  'B_INCLUSION': 2,\n",
    "#  'I_EXCLUSION': 0,\n",
    "#  'I_INCLUSION': 3,\n",
    "#  'O': 4,\n",
    "#  'X': 5,\n",
    "#  '[CLS]':6,\n",
    "#  '[SEP]':7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "TTHSQyY6gM39"
   },
   "outputs": [],
   "source": [
    "tag2idx={'B_INCLUSION': 0,\n",
    " 'U_INCLUSION': 1,\n",
    " 'I_INCLUSION': 2,\n",
    " 'i_EXCLUSION': 3,\n",
    " 'O': 4,\n",
    " 'U_EXCLUSION': 5,\n",
    " 'I_EXCLUSION': 6,\n",
    " 'B_EXCLUSION': 7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vg47n-qXCdTI",
    "outputId": "97f37910-58c7-4a6b-b55c-1006d6c047f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B_EXCLUSION': 7,\n",
       " 'B_INCLUSION': 0,\n",
       " 'I_EXCLUSION': 6,\n",
       " 'I_INCLUSION': 2,\n",
       " 'O': 4,\n",
       " 'U_EXCLUSION': 5,\n",
       " 'U_INCLUSION': 1,\n",
       " 'i_EXCLUSION': 3}"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "QS0y4GihCdTJ"
   },
   "outputs": [],
   "source": [
    "# Mapping index to name\n",
    "tag2name={tag2idx[key] : key for key in tag2idx.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "K5Xj8UVSCdTJ"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dyJ3I-JDCdTL",
    "outputId": "30e1cad0-297a-4af7-e29c-fb9fa5670369"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "p3__v5BXCdTM"
   },
   "outputs": [],
   "source": [
    "# Manual define vocabulary address, if you download the tokenzier file in local\n",
    "# vocab.txt, download from: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt\n",
    "#vocabulary = \"models/bert-base-cased/vocab.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "be-fKROVCdTM"
   },
   "outputs": [],
   "source": [
    "# Len of the sentence must be not bigger than the training model\n",
    "# See model's 'max_position_embeddings' = 512\n",
    "max_len  = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RoqNCztCD2UF",
    "outputId": "0e8d774c-3197-4760-a9aa-1bff224420f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-pretrained-bert\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
      "\r",
      "\u001b[K     |██▋                             | 10kB 16.9MB/s eta 0:00:01\r",
      "\u001b[K     |█████▎                          | 20kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 30kB 22.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▋                     | 40kB 24.9MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 51kB 25.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▉                | 61kB 27.9MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▌             | 71kB 18.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▏          | 81kB 19.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▉        | 92kB 17.9MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▌     | 102kB 18.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▏  | 112kB 18.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▊| 122kB 18.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 133kB 18.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.8.1+cu101)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (4.41.1)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.19.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
      "Collecting boto3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/8f/42959300c543b4d34bc9f9b54954471a33384c181084ed84f070763d7f37/boto3-1.17.62-py2.py3-none-any.whl (131kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 34.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.7.4.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
      "Collecting botocore<1.21.0,>=1.20.62\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/60/ba830f93176fdc23166043298173ee2aecd5cf150f1ede51d6506f021deb/botocore-1.20.62-py2.py3-none-any.whl (7.5MB)\n",
      "\u001b[K     |████████████████████████████████| 7.5MB 42.1MB/s \n",
      "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
      "Collecting s3transfer<0.5.0,>=0.4.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/d0/693477c688348654ddc21dcdce0817653a294aa43f41771084c25e7ff9c7/s3transfer-0.4.2-py2.py3-none-any.whl (79kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 11.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.62->boto3->pytorch-pretrained-bert) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.62->boto3->pytorch-pretrained-bert) (1.15.0)\n",
      "\u001b[31mERROR: botocore 1.20.62 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n",
      "Successfully installed boto3-1.17.62 botocore-1.20.62 jmespath-0.10.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-pretrained-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "lDe5AtKxFxnp"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "pDEs_tJ5CdTM"
   },
   "outputs": [],
   "source": [
    "# load tokenizer, with manual file address or pretrained address\n",
    "#tokenizer=BertTokenizer(vocab_file=vocabulary,do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FF0N5qTsVfcS",
    "outputId": "a2607050-74a5-4419-9fb5-13f38ae8c34b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_pretrained_bert.tokenization:The pre-trained model you are loading is a cased model but you have not set `do_lower_case` to False. We are setting `do_lower_case=False` for you but you may want to check this behavior.\n",
      "INFO:pytorch_pretrained_bert.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt not found in cache, downloading to /tmp/tmph61ozod2\n",
      "100%|██████████| 213450/213450 [00:00<00:00, 23789604.57B/s]\n",
      "INFO:pytorch_pretrained_bert.file_utils:copying /tmp/tmph61ozod2 to cache at /root/.pytorch_pretrained_bert/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n",
      "INFO:pytorch_pretrained_bert.file_utils:creating metadata file for /root/.pytorch_pretrained_bert/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n",
      "INFO:pytorch_pretrained_bert.file_utils:removing temp file /tmp/tmph61ozod2\n",
      "INFO:pytorch_pretrained_bert.tokenization:loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /root/.pytorch_pretrained_bert/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n"
     ]
    }
   ],
   "source": [
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DfuHptgzCdTN",
    "outputId": "e966bda1-334e-4c19-c722-95d2bfc761cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.0,len:20\n",
      "texts:[CLS] Includes programs such as group exercise adult education classes recreation nut ##rit ##ious meals and social work services [SEP]\n",
      "No.0,len:20\n",
      "lables:[CLS] O O O O B_INCLUSION I_INCLUSION B_INCLUSION I_INCLUSION I_INCLUSION U_INCLUSION B_INCLUSION X X I_INCLUSION O B_INCLUSION I_INCLUSION I_INCLUSION [SEP]\n",
      "No.1,len:21\n",
      "texts:[CLS] 4 ) Op ##io ##id use disorder treatment services are covered under Part B of Original Me ##dic ##are [SEP]\n",
      "No.1,len:21\n",
      "lables:[CLS] O X B_INCLUSION X X I_INCLUSION I_INCLUSION I_INCLUSION O O O O O X O O O X X [SEP]\n",
      "No.2,len:39\n",
      "texts:[CLS] Op ##tional Su ##pp ##lement ##al Pack ##age 2 - Dental and Vision Pack ##age covers prevent ##ive rest ##ora ##tive end ##od ##ont ##ic period ##ont ##ic and oral surgery dental services and vision eye ##wear [SEP]\n",
      "No.2,len:39\n",
      "lables:[CLS] O X O X X X O X X O O O O O X O U_INCLUSION X U_INCLUSION X X U_INCLUSION X X X U_INCLUSION X X O B_INCLUSION I_INCLUSION I_INCLUSION I_INCLUSION O B_INCLUSION I_INCLUSION X [SEP]\n",
      "No.3,len:14\n",
      "texts:[CLS] 1 ) The plan will pay up to for in - network [SEP]\n",
      "No.3,len:14\n",
      "lables:[CLS] O X O O O O O O O B_INCLUSION X X [SEP]\n",
      "No.4,len:12\n",
      "texts:[CLS] Ben ##ef ##its are available only through Liberty Dental providers [SEP]\n",
      "No.4,len:12\n",
      "lables:[CLS] O X X O O O O B_INCLUSION I_INCLUSION I_INCLUSION [SEP]\n"
     ]
    }
   ],
   "source": [
    "tokenized_texts = []\n",
    "word_piece_labels = []\n",
    "i_inc = 0\n",
    "for word_list,label in (zip(sentences,labels)):\n",
    "    temp_lable = []\n",
    "    temp_token = []\n",
    "    \n",
    "    # Add [CLS] at the front \n",
    "    temp_lable.append('[CLS]')\n",
    "    temp_token.append('[CLS]')\n",
    "    \n",
    "    for word,lab in zip(word_list,label):\n",
    "        token_list = tokenizer.tokenize(word)\n",
    "        for m,token in enumerate(token_list):\n",
    "            temp_token.append(token)\n",
    "            if m==0:\n",
    "                temp_lable.append(lab)\n",
    "            else:\n",
    "                temp_lable.append('X')  \n",
    "                \n",
    "    # Add [SEP] at the end\n",
    "    temp_lable.append('[SEP]')\n",
    "    temp_token.append('[SEP]')\n",
    "    \n",
    "    tokenized_texts.append(temp_token)\n",
    "    word_piece_labels.append(temp_lable)\n",
    "    \n",
    "    if 5 > i_inc:\n",
    "        print(\"No.%d,len:%d\"%(i_inc,len(temp_token)))\n",
    "        print(\"texts:%s\"%(\" \".join(temp_token)))\n",
    "        print(\"No.%d,len:%d\"%(i_inc,len(temp_lable)))\n",
    "        print(\"lables:%s\"%(\" \".join(temp_lable)))\n",
    "    i_inc +=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qmrKscXoCdTO",
    "outputId": "57dc539b-01db-4a53-d0b8-45c9ed552ce9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  101 25051  2648  1216  1112  1372  6730  4457  1972  3553 12729 22664\n",
      "  7729  4179 13077  1105  1934  1250  1826   102     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "# Make text token into id\n",
    "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
    "                          maxlen=max_len, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "print(input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YDRPjtdPCdTO",
    "outputId": "18fe841c-a5dd-497f-ea96-54387b2cfaa8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan  4.  4.  4.  4.  0.  2.  0.  2.  2.  1.  0. nan nan  2.  4.  0.  2.\n",
      "  2. nan  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.\n",
      "  4.  4.  4.  4.  4.  4.  4.  4.  4.]\n"
     ]
    }
   ],
   "source": [
    "# Make label into id, pad with \"O\" meaning others\n",
    "tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in word_piece_labels],\n",
    "                     maxlen=max_len, value=tag2idx[\"O\"], padding=\"post\",\n",
    "                     dtype=\"float\", truncating=\"post\")\n",
    "print(tags[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "ULqyqIx8CdTO"
   },
   "outputs": [],
   "source": [
    "tags[np.isnan(tags)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nyG7TxDkCdTP",
    "outputId": "595d6d49-69be-4ddf-b928-c4359d58e74a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 4. 4. 4. 4. 0. 2. 0. 2. 2. 1. 0. 0. 0. 2. 4. 0. 2. 2. 0. 4. 4. 4. 4.\n",
      " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.]\n"
     ]
    }
   ],
   "source": [
    "print(tags[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "M4Q8RNG5CdTP"
   },
   "outputs": [],
   "source": [
    "# For fine tune of predict, with token mask is 1,pad token is 0\n",
    "attention_masks = [[int(i>0) for i in ii] for ii in input_ids]\n",
    "attention_masks[0];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "Omx2T9YzCdTP"
   },
   "outputs": [],
   "source": [
    "# Since only one sentence, all the segment set to 0\n",
    "segment_ids = [[0] * len(input_id) for input_id in input_ids]\n",
    "segment_ids[0];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "C0BLDf3PCdTQ"
   },
   "outputs": [],
   "source": [
    "tr_inputs, val_inputs, tr_tags, val_tags,tr_masks, val_masks,tr_segs, val_segs = train_test_split(input_ids, tags,attention_masks,segment_ids, \n",
    "                                                            random_state=4, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SWAzUu8TCdTQ",
    "outputId": "a5774807-0b69-4372-986c-e962e29aa8fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 50, 200, 50)"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tr_inputs),len(val_inputs),len(tr_segs),len(val_segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "mz_zDWhECdTQ"
   },
   "outputs": [],
   "source": [
    "tr_inputs = torch.tensor(tr_inputs)\n",
    "val_inputs = torch.tensor(val_inputs)\n",
    "tr_tags = torch.tensor(tr_tags)\n",
    "val_tags = torch.tensor(val_tags)\n",
    "tr_masks = torch.tensor(tr_masks)\n",
    "val_masks = torch.tensor(val_masks)\n",
    "tr_segs = torch.tensor(tr_segs)\n",
    "val_segs = torch.tensor(val_segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "ZpmlIdClCdTR"
   },
   "outputs": [],
   "source": [
    "# Set batch num\n",
    "batch_num = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "y6HsdpfOCdTR"
   },
   "outputs": [],
   "source": [
    "# Only set token embedding, attention embedding, no segment embedding\n",
    "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "# Drop last can make batch training better for the last one\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_num,drop_last=True)\n",
    "\n",
    "valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
    "valid_sampler = SequentialSampler(valid_data)\n",
    "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=batch_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "5RIK-ogzCdTR"
   },
   "outputs": [],
   "source": [
    "# #train_data = torch.tensor(train_data)\n",
    "# #validation_inputs = torch.tensor(validation_inputs)\n",
    "# train_labels = torch.tensor(train_labels, dtype=torch.long)\n",
    "# validation_labels = torch.tensor(validation_labels, dtype=torch.long)\n",
    "# train_masks = torch.tensor(train_masks, dtype=torch.long)\n",
    "# validation_masks = torch.tensor(validation_masks, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "7uz8mYPzCdTS"
   },
   "outputs": [],
   "source": [
    "# In this folder, contain model confg(json) and model weight(bin) files\n",
    "# pytorch_model.bin, download from: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin\n",
    "# config.json, downlaod from: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json\n",
    "#model_file_address = 'models/bert-base-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "exwgXZfHCdTS",
    "outputId": "af1d04f1-0eac-4d61-9add-b47ccbf68a51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tag2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286,
     "referenced_widgets": [
      "cbb8c7bf7899439e9ced554912334527",
      "b42042e06e734c93ae091bc6a3720804",
      "0228fc0583444636bf2bc92f83f53cb4",
      "910e0b344a7e4a8982959d9ae791a5fb",
      "41d4afcf02a644daa22edb88c4ecc3f8",
      "672b6fc956fd481caa70d824c2bc1497",
      "84f79d21a6ac4dcfaf6e31b7c5951e33",
      "38427f3a385745fc83f6213e959e911a",
      "258046856ac54a46beda80683cdd24f4",
      "d2f923f4f1984e4fbce147a7c7ed4429",
      "2c36f5eccd884e18bea9d54eef560256",
      "a8455efbba974124b6ba057aff68ed01",
      "31bfdc18004d4614a819e122227db0e5",
      "6052d62cf1144acca8dcaba39ca5295d",
      "4a8e68ea8ead4fae86d7b8624fb95d65",
      "2effd0bbb9a8458f827845e59030075e"
     ]
    },
    "id": "RVMllj6UCdTT",
    "outputId": "eb226388-e1e7-43f5-acce-53c4ce460a1c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140650088181584 acquired on /root/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbb8c7bf7899439e9ced554912334527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140650088181584 released on /root/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307.lock\n",
      "INFO:filelock:Lock 140650079003984 acquired on /root/.cache/huggingface/transformers/092cc582560fc3833e556b3f833695c26343cb54b7e88cd02d40821462a74999.1f48cab6c959fc6c360d22bea39d06959e90f5b002e77e836d2da45464875cda.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "258046856ac54a46beda80683cdd24f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435779157.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140650079003984 released on /root/.cache/huggingface/transformers/092cc582560fc3833e556b3f833695c26343cb54b7e88cd02d40821462a74999.1f48cab6c959fc6c360d22bea39d06959e90f5b002e77e836d2da45464875cda.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Will load config and weight with from_pretrained()\n",
    "#model = BertForTokenClassification.from_pretrained(model_file_address,num_labels=len(tag2idx))\n",
    "model = BertForTokenClassification.from_pretrained(\"bert-base-cased\", num_labels=len(tag2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "j71lbd-7CdTT"
   },
   "outputs": [],
   "source": [
    "model;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "SZhQTdAbCdTT"
   },
   "outputs": [],
   "source": [
    "# Set model to GPU,if you are using GPU machine\n",
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "QCbpN_oPCdTT"
   },
   "outputs": [],
   "source": [
    "# Add multi GPU support\n",
    "if n_gpu >1:\n",
    "    model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "U88E-hFeCdTU"
   },
   "outputs": [],
   "source": [
    "# Set epoch and grad max num\n",
    "epochs = 2\n",
    "max_grad_norm = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "s7eCgB9LCdTU"
   },
   "outputs": [],
   "source": [
    "# Cacluate train optimiazaion num\n",
    "num_train_optimization_steps = int( math.ceil(len(tr_inputs) / batch_num) / 1) * epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "yUAV1foxCdTU"
   },
   "outputs": [],
   "source": [
    "# True: fine tuning all the layers \n",
    "# False: only fine tuning the classifier layers\n",
    "FULL_FINETUNING = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "owvq_ZTcCdTU"
   },
   "outputs": [],
   "source": [
    "if FULL_FINETUNING:\n",
    "    # Fine tune model all layer parameters\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'gamma', 'beta']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.0}\n",
    "    ]\n",
    "else:\n",
    "    # Only fine tune classifier parameters\n",
    "    param_optimizer = list(model.classifier.named_parameters()) \n",
    "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "BV2j6whSCdTV"
   },
   "outputs": [],
   "source": [
    "# TRAIN loop\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wcpbAE_sCdTV",
    "outputId": "fc845c59-5757-4171-c715-3a022c9c06e2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 200\n",
      "  Batch size = 1\n",
      "  Num steps = 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  50%|█████     | 1/2 [00:13<00:13, 13.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7629079227522015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 2/2 [00:27<00:00, 13.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3871274642483331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"***** Running training *****\")\n",
    "print(\"  Num examples = %d\"%(len(tr_inputs)))\n",
    "print(\"  Batch size = %d\"%(batch_num))\n",
    "print(\"  Num steps = %d\"%(num_train_optimization_steps))\n",
    "for _ in trange(epochs,desc=\"Epoch\"):\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # add batch to gpu\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "          ###############Bug fix code####################\n",
    "        b_input_ids = b_input_ids.type(torch.LongTensor)\n",
    "        b_input_mask = b_input_mask.type(torch.LongTensor)\n",
    "        b_labels = b_labels.type(torch.LongTensor)\n",
    "\n",
    "        b_input_ids = b_input_ids.to(device)\n",
    "        b_input_mask = b_input_mask.to(device)\n",
    "        b_labels = b_labels.to(device)\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(b_input_ids, token_type_ids=None,\n",
    "        attention_mask=b_input_mask, labels=b_labels)\n",
    "        loss, scores = outputs[:2]\n",
    "        if n_gpu>1:\n",
    "            # When multi gpu, average it\n",
    "            loss = loss.mean()\n",
    "        \n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # track train loss\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        \n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "        \n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    # print train loss per epoch\n",
    "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "B0qErfQhCdTW"
   },
   "outputs": [],
   "source": [
    "bert_out_address = 'sample_data/models/bert_out_model/en09'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "2fzTyDf2CdTW"
   },
   "outputs": [],
   "source": [
    "# Make dir if not exits\n",
    "if not os.path.exists(bert_out_address):\n",
    "        os.makedirs(bert_out_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "N5nGM9mWCdTW"
   },
   "outputs": [],
   "source": [
    "# Save a trained model, configuration and tokenizer\n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "-rVvr3d-CdTW"
   },
   "outputs": [],
   "source": [
    "# If we save using the predefined names, we can load using `from_pretrained`\n",
    "output_model_file = os.path.join(bert_out_address, \"pytorch_model.bin\")\n",
    "output_config_file = os.path.join(bert_out_address, \"config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "EuGVhpY3CdTX",
    "outputId": "54d4bf5b-634b-43d1-ec73-da582001c5fb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'sample_data/models/bert_out_model/en09/vocab.txt'"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model into file\n",
    "torch.save(model_to_save.state_dict(), output_model_file)\n",
    "model_to_save.config.to_json_file(output_config_file)\n",
    "tokenizer.save_vocabulary(bert_out_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "RB7HN8-YCdTX"
   },
   "outputs": [],
   "source": [
    "model = BertForTokenClassification.from_pretrained(bert_out_address,num_labels=len(tag2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "XiUDg7baCdTX"
   },
   "outputs": [],
   "source": [
    "# Set model to GPU\n",
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "of1164_HCdTX"
   },
   "outputs": [],
   "source": [
    "if n_gpu >1:\n",
    "    model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "22pzKhqUCdTY"
   },
   "outputs": [],
   "source": [
    "# Evalue loop\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1DKBbVn8CdTY",
    "outputId": "9e90e663-236a-4a1f-b162-75f43cb6fd1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running evaluation *****\n",
      "  Num examples =50\n",
      "  Batch size = 1\n",
      "f1 socre: 0.781427\n",
      "['B_INCLUSION', 'O', 'B_INCLUSION', 'B_INCLUSION', 'B_INCLUSION', 'B_INCLUSION', 'I_INCLUSION', 'I_INCLUSION', 'B_INCLUSION', 'O', 'O', 'O', 'O', 'O', 'B_INCLUSION', 'O', 'O', 'O', 'O', 'O', 'B_INCLUSION', 'B_INCLUSION', 'B_INCLUSION', 'O', 'B_INCLUSION', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B_INCLUSION']\n",
      "['B_INCLUSION', 'O', 'B_INCLUSION', 'B_INCLUSION', 'B_INCLUSION', 'B_INCLUSION', 'I_INCLUSION', 'I_INCLUSION', 'B_INCLUSION', 'O', 'O', 'O', 'O', 'O', 'B_INCLUSION', 'O', 'O', 'O', 'O', 'O', 'B_INCLUSION', 'B_INCLUSION', 'B_INCLUSION', 'O', 'B_INCLUSION', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B_INCLUSION']\n",
      "Accuracy score: 0.843794\n",
      "***** Eval results *****\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  _EXCLUSION     0.5385    0.2333    0.3256        30\n",
      "  _INCLUSION     0.7916    0.8184    0.8048       413\n",
      "\n",
      "   micro avg     0.7841    0.7788    0.7814       443\n",
      "   macro avg     0.6650    0.5259    0.5652       443\n",
      "weighted avg     0.7744    0.7788    0.7723       443\n",
      "\n",
      "f1 socre: 0.781427\n",
      "Accuracy score: 0.843794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_INCLUSION seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_INCLUSION seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: U_INCLUSION seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_EXCLUSION seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_EXCLUSION seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: U_EXCLUSION seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    }
   ],
   "source": [
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "print(\"***** Running evaluation *****\")\n",
    "print(\"  Num examples ={}\".format(len(val_inputs)))\n",
    "print(\"  Batch size = {}\".format(batch_num))\n",
    "for step, batch in enumerate(valid_dataloader):\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    input_ids, input_mask, label_ids = batch\n",
    "      ###############Bug fix code####################\n",
    "#     input_ids = input_ids.type(torch.LongTensor)\n",
    "#     input_mask = input_mask.type(torch.LongTensor)\n",
    "#     label_ids = label_ids.type(torch.LongTensor)\n",
    "\n",
    "#     input_ids = input_ids.to(device)\n",
    "#     input_mask = input_mask.to(device)\n",
    "#     label_ids = label_ids.to(device)\n",
    "    \n",
    "#     input_ids = torch.where(torch.isnan(input_ids), torch.zeros_like(input_ids), input_ids)\n",
    "#     input_mask = torch.where(torch.isnan(input_mask), torch.zeros_like(input_mask), input_mask)\n",
    "#     label_ids = torch.where(torch.isnan(label_ids), torch.zeros_like(label_ids), label_ids)\n",
    "    #print(input_ids)\n",
    "    \n",
    "#     if step > 2:\n",
    "#         break\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, token_type_ids=None,\n",
    "        attention_mask=input_mask,)\n",
    "        # For eval mode, the first result of outputs is logits\n",
    "        logits = outputs[0] \n",
    "    \n",
    "    # Get NER predict result\n",
    "    logits = torch.argmax(F.log_softmax(logits,dim=2),dim=2)\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    \n",
    "    \n",
    "    # Get NER true result\n",
    "    label_ids = label_ids.to('cpu').numpy()\n",
    "    \n",
    "    \n",
    "    # Only predict the real word, mark=0, will not calculate\n",
    "    input_mask = input_mask.to('cpu').numpy()\n",
    "    \n",
    "    # Compare the valuable predict result\n",
    "    for i,mask in enumerate(input_mask):\n",
    "        # Real one\n",
    "        temp_1 = []\n",
    "        # Predict one\n",
    "        temp_2 = []\n",
    "        \n",
    "        for j, m in enumerate(mask):\n",
    "            # Mark=0, meaning its a pad word, dont compare\n",
    "            if m:\n",
    "                if tag2name[label_ids[i][j]] != \"X\" and tag2name[label_ids[i][j]] != \"[CLS]\" and tag2name[label_ids[i][j]] != \"[SEP]\" : # Exclude the X label\n",
    "                    temp_1.append(tag2name[label_ids[i][j]])\n",
    "                    temp_2.append(tag2name[logits[i][j]])\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "            \n",
    "        y_true.append(temp_1)\n",
    "        y_pred.append(temp_2)\n",
    "\n",
    "        \n",
    "\n",
    "print(\"f1 socre: %f\"%(f1_score(y_true, y_pred)))\n",
    "print(y_true[0])\n",
    "print(y_pred[0])\n",
    "print(\"Accuracy score: %f\"%(accuracy_score(y_true, y_pred)))\n",
    "\n",
    "# Get acc , recall, F1 result report\n",
    "report = classification_report(y_true, y_pred,digits=4)\n",
    "\n",
    "# Save the report into file\n",
    "output_eval_file = os.path.join(bert_out_address, \"eval_results.txt\")\n",
    "with open(output_eval_file, \"w\") as writer:\n",
    "    print(\"***** Eval results *****\")\n",
    "    print(\"\\n%s\"%(report))\n",
    "    print(\"f1 socre: %f\"%(f1_score(y_true, y_pred)))\n",
    "    print(\"Accuracy score: %f\"%(accuracy_score(y_true, y_pred)))\n",
    "    \n",
    "    writer.write(\"f1 socre:\\n\")\n",
    "    writer.write(str(f1_score(y_true, y_pred)))\n",
    "    writer.write(\"\\n\\nAccuracy score:\\n\")\n",
    "    writer.write(str(accuracy_score(y_true, y_pred)))\n",
    "    writer.write(\"\\n\\n\")  \n",
    "    writer.write(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "9rYCoc4JCdTZ"
   },
   "outputs": [],
   "source": [
    "# Model we trained before, the dir containing pytorch_model.bin and vocab.txt\n",
    "save_model_address = 'sample_data/models/bert_out_model/en09'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "pMM9JJzWCdTZ"
   },
   "outputs": [],
   "source": [
    "save_model = BertForTokenClassification.from_pretrained(save_model_address,num_labels=len(tag2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x2IuxwubCdTZ",
    "outputId": "b21050e3-086d-4fcf-e194-589709ea68c4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.tokenization:loading vocabulary file sample_data/models/bert_out_model/en09/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "# Here, our save model address containing pytorch_model.bin and vocab.txt\n",
    "# So, we can load the tokenzier from the same dir as the save model address\n",
    "tokenizer = BertTokenizer.from_pretrained(save_model_address,do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "BZYJ0IOxCdTa"
   },
   "outputs": [],
   "source": [
    "# Set max sentence length, must be the same as our training process\n",
    "max_len  = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "a7-TJV9ACdTa"
   },
   "outputs": [],
   "source": [
    "test_query = \"Includes programs such as group exercise, adult education classes, recreation, nutritious meals, and social work services.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "1iSXZnYXCdTa"
   },
   "outputs": [],
   "source": [
    "tokenized_texts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "vAx6q8IGCdTa"
   },
   "outputs": [],
   "source": [
    "temp_token = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "DfaNJcr1CdTb"
   },
   "outputs": [],
   "source": [
    "# Add [CLS] at the front \n",
    "temp_token.append('[CLS]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "PSoV5JcOCdTb"
   },
   "outputs": [],
   "source": [
    "token_list = tokenizer.tokenize(test_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "90YXWQ3FCdTb"
   },
   "outputs": [],
   "source": [
    "#token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "lKew_p-0CdTb"
   },
   "outputs": [],
   "source": [
    "for m,token in enumerate(token_list):\n",
    "    temp_token.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "X66yRE0vCdTb"
   },
   "outputs": [],
   "source": [
    "# Trim the token to fit the length requirement\n",
    "if len(temp_token) > max_len-1:\n",
    "    temp_token= temp_token[:max_len-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "CNfGXRPbCdTc"
   },
   "outputs": [],
   "source": [
    "# Add [SEP] at the end\n",
    "temp_token.append('[SEP]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SWjbpyAJCdTc",
    "outputId": "4472b57f-a6ae-4b52-dfef-26fe11301116"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'Includes',\n",
       " 'programs',\n",
       " 'such',\n",
       " 'as',\n",
       " 'group',\n",
       " 'exercise',\n",
       " ',',\n",
       " 'adult',\n",
       " 'education',\n",
       " 'classes',\n",
       " ',',\n",
       " 'recreation',\n",
       " ',',\n",
       " 'nut',\n",
       " '##rit',\n",
       " '##ious',\n",
       " 'meals',\n",
       " ',',\n",
       " 'and',\n",
       " 'social',\n",
       " 'work',\n",
       " 'services',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 85,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "XrYUbjEhCdTc"
   },
   "outputs": [],
   "source": [
    "\n",
    "tokenized_texts.append(temp_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mHAKosayCdTc",
    "outputId": "b7e6ee8d-d9eb-48f4-da93-e9dc55f0b793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  101 25051  2648  1216  1112  1372  6730   117  4457  1972  3553   117\n",
      " 12729   117 22664  7729  4179 13077   117  1105  1934  1250  1826   119\n",
      "   102     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "# Make text token into id\n",
    "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
    "                          maxlen=max_len, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "print(input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "BgijhNuFCdTd"
   },
   "outputs": [],
   "source": [
    "# For fine tune of predict, with token mask is 1,pad token is 0\n",
    "attention_masks = [[int(i>0) for i in ii] for ii in input_ids]\n",
    "attention_masks[0];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "c0DEb56ZCdTd"
   },
   "outputs": [],
   "source": [
    "segment_ids = [[0] * len(input_id) for input_id in input_ids]\n",
    "segment_ids[0];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "WuOmx9m8CdTd"
   },
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(input_ids)\n",
    "attention_masks = torch.tensor(attention_masks)\n",
    "segment_ids = torch.tensor(segment_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "gWn8NBNKCdTd"
   },
   "outputs": [],
   "source": [
    "# Set save model to Evalue loop\n",
    "save_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "TuimBD4SCdTe"
   },
   "outputs": [],
   "source": [
    "# Get model predict result\n",
    "with torch.no_grad():\n",
    "        outputs = save_model(input_ids, token_type_ids=None,\n",
    "        attention_mask=None,)\n",
    "        # For eval mode, the first result of outputs is logits\n",
    "        logits = outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "cy5lb9eSCdTe"
   },
   "outputs": [],
   "source": [
    "# Make logits into numpy type predict result\n",
    "# The predict result contain each token's all tags predict result\n",
    "predict_results = logits.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hqaUA2TjCdTe",
    "outputId": "f643d8ef-0ea0-4b38-a745-38ea6ca2eb2c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 45, 8)"
      ]
     },
     "execution_count": 94,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "icHki3_ZCdTe"
   },
   "outputs": [],
   "source": [
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "3Hc70gp9CdTf"
   },
   "outputs": [],
   "source": [
    "result_arrays_soft = softmax(predict_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xv_jwNGwCdTf",
    "outputId": "5935453b-2cb6-4e62-b65f-a05c9965764f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.1015027e-01, 2.8547707e-05, 9.8267097e-05, 2.9940004e-05,\n",
       "       9.0841386e-05, 2.3996403e-05, 1.6651111e-05, 3.6762620e-05],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_arrays_soft[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "QqtSF9ZgCdTf"
   },
   "outputs": [],
   "source": [
    "result_array = result_arrays_soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dfgwy957CdTf",
    "outputId": "ffac7658-8438-420d-e9f8-d3f9aafeb04f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 8)"
      ]
     },
     "execution_count": 99,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result_array),len(result_array[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "JawQpPCqCdTg"
   },
   "outputs": [],
   "source": [
    "# Get each token final predict tag index result\n",
    "result_list = np.argmax(result_array,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1YNeetrgoEDv",
    "outputId": "3428923d-fe7e-4428-9dfe-adf3370e153a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 4 4 4 4 0 2 4 0 2 2 4 0 4 0 0 0 2 4 4 0 2 2 0 0 4 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QNgHZU3bCdTg",
    "outputId": "a1ca24c7-0baf-4301-fcda-5b01d344fd22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token:[CLS]\n",
      "Tag:0\n",
      "Predict_Tag:B_INCLUSION\n",
      "\n",
      "Token:Includes\n",
      "Tag:4\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:programs\n",
      "Tag:4\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:such\n",
      "Tag:4\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:as\n",
      "Tag:4\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:group\n",
      "Tag:0\n",
      "Predict_Tag:B_INCLUSION\n",
      "\n",
      "Token:exercise\n",
      "Tag:2\n",
      "Predict_Tag:I_INCLUSION\n",
      "\n",
      "Token:,\n",
      "Tag:4\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:adult\n",
      "Tag:0\n",
      "Predict_Tag:B_INCLUSION\n",
      "\n",
      "Token:education\n",
      "Tag:2\n",
      "Predict_Tag:I_INCLUSION\n",
      "\n",
      "Token:classes\n",
      "Tag:2\n",
      "Predict_Tag:I_INCLUSION\n",
      "\n",
      "Token:,\n",
      "Tag:4\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:recreation\n",
      "Tag:0\n",
      "Predict_Tag:B_INCLUSION\n",
      "\n",
      "Token:,\n",
      "Tag:4\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:nut\n",
      "Tag:0\n",
      "Predict_Tag:B_INCLUSION\n",
      "\n",
      "Token:##rit\n",
      "Tag:0\n",
      "Predict_Tag:B_INCLUSION\n",
      "\n",
      "Token:##ious\n",
      "Tag:0\n",
      "Predict_Tag:B_INCLUSION\n",
      "\n",
      "Token:meals\n",
      "Tag:2\n",
      "Predict_Tag:I_INCLUSION\n",
      "\n",
      "Token:,\n",
      "Tag:4\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:and\n",
      "Tag:4\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:social\n",
      "Tag:0\n",
      "Predict_Tag:B_INCLUSION\n",
      "\n",
      "Token:work\n",
      "Tag:2\n",
      "Predict_Tag:I_INCLUSION\n",
      "\n",
      "Token:services\n",
      "Tag:2\n",
      "Predict_Tag:I_INCLUSION\n",
      "\n",
      "Token:.\n",
      "Tag:0\n",
      "Predict_Tag:B_INCLUSION\n",
      "\n",
      "Token:[SEP]\n",
      "Tag:0\n",
      "Predict_Tag:B_INCLUSION\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, mark in enumerate(attention_masks[0]):\n",
    "    if mark>0:\n",
    "        print(\"Token:%s\"%(temp_token[i]))\n",
    "        print(\"Tag:%s\"%(result_list[i]))\n",
    "        print(\"Predict_Tag:%s\"%(tag2name[result_list[i]]))\n",
    "        #print(\"Posibility:%f\"%(result_array[i][result_list[i]]))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "yx3eN5w2CdTg"
   },
   "outputs": [],
   "source": [
    "####Prediction#####\n",
    "def bert_iob_predict(input_sentence):\n",
    "    tokenized_texts = []\n",
    "    temp_token = []\n",
    "    temp_token.append('[CLS]')\n",
    "    token_list = tokenizer.tokenize(input_sentence)\n",
    "    for m,token in enumerate(token_list):\n",
    "        inc_string = \"\"\n",
    "        exc_string = \"\"\n",
    "        temp_token.append(token)\n",
    "    if len(temp_token) > max_len-1:\n",
    "        temp_token= temp_token[:max_len-1]\n",
    "    temp_token.append('[SEP]')\n",
    "    tokenized_texts.append(temp_token)\n",
    "    input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
    "                          maxlen=max_len, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "    attention_masks = [[int(i>0) for i in ii] for ii in input_ids]\n",
    "    segment_ids = [[0] * len(input_id) for input_id in input_ids]\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "    segment_ids = torch.tensor(segment_ids)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "       logits = model(b_input_ids, token_type_ids=None,\n",
    "                       attention_mask=b_input_mask)\n",
    "       logits = logits[0]\n",
    "        \n",
    "        # For eval mode, the first result of outputs is logits\n",
    "    predict_results = logits.detach().cpu().numpy()\n",
    "    # print(predict_results)\n",
    "    result_arrays_soft = softmax(predict_results[0])\n",
    "    #result_list = np.argmax(result_array,axis=-1)\n",
    "    result_array = result_arrays_soft\n",
    "    tags_pred = []\n",
    "    token_pred = []\n",
    "    for i, mark in enumerate(attention_masks[0]):\n",
    "        if mark>0:\n",
    "            # print(\"Token:%s\"%(temp_token[i]))\n",
    "            token_pred.append(temp_token[i])\n",
    "            #print(\"Tag:%s\"%(result_list[i]))\n",
    "            # print(\"Predict_Tag:%s\"%(tag2name[result_list[i]]))\n",
    "            tags_pred.append(tag2name[result_list[i]])\n",
    "            #print(\"Posibility:%f\"%(result_array[i][result_list[i]]))\n",
    "            # print()\n",
    "    \n",
    "    # tag2name[result_list[i]],\n",
    "    return token_pred,tags_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gqy9VXMbCdTh",
    "outputId": "70a6885a-0860-4fb5-f37e-6b57c555cf0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 5.84272480e+00 -1.84926176e+00 -1.44894814e+00 -1.00105929e+00\n",
      "   -1.07198015e-01 -1.20104909e+00 -6.23666346e-01 -8.77204299e-01]\n",
      "  [-5.95146537e-01 -1.27668142e+00 -6.88408494e-01 -1.18680918e+00\n",
      "    1.94140124e+00 -1.19454074e+00  2.51594394e-01  1.37233949e+00]\n",
      "  [-4.55421954e-01 -1.90294170e+00  2.25076243e-01 -1.51298165e+00\n",
      "    1.10198963e+00 -1.59963655e+00  2.77515721e+00 -4.55001473e-01]\n",
      "  [-6.34152532e-01 -1.25586891e+00  7.43330568e-02 -1.09170032e+00\n",
      "    9.13674593e-01 -1.45986032e+00  2.65231776e+00  1.02290407e-01]\n",
      "  [-1.72603679e+00 -1.38210356e+00  1.27796662e+00 -1.32638752e+00\n",
      "    7.64644384e-01 -1.09266877e+00  2.90312958e+00  2.26431713e-01]\n",
      "  [-2.24379945e+00 -1.62933481e+00  1.74564564e+00 -1.09507024e+00\n",
      "    8.41328740e-01 -9.76149917e-01  2.94238305e+00 -6.20005786e-01]\n",
      "  [-2.01485372e+00 -1.51138818e+00  2.33449054e+00 -1.46519458e+00\n",
      "    1.56571376e+00 -1.39859390e+00  3.12493777e+00 -8.57932985e-01]\n",
      "  [-1.85880125e+00 -1.25057399e+00 -1.48262167e+00 -1.64603746e+00\n",
      "    6.45034027e+00 -1.08703089e+00  1.65366009e-01  1.97170496e-01]\n",
      "  [-1.62006068e+00 -1.30065846e+00 -1.44537115e+00 -1.64421666e+00\n",
      "    6.55584002e+00 -1.52799582e+00  2.49625683e-01 -1.71686560e-01]\n",
      "  [-1.43490601e+00 -1.60969138e+00 -1.24022877e+00 -1.67509949e+00\n",
      "    6.51491880e+00 -1.18091476e+00  1.31305888e-01  2.12896569e-03]\n",
      "  [-1.67681861e+00 -1.26600528e+00 -1.40029335e+00 -1.57423246e+00\n",
      "    6.12728024e+00 -1.26318014e+00  3.94699663e-01  5.15340194e-02]\n",
      "  [-7.82660007e-01 -1.60102630e+00 -1.17785823e+00 -1.81233025e+00\n",
      "    4.62183905e+00 -1.13132906e+00  8.02879155e-01  4.05688107e-01]\n",
      "  [-2.00862932e+00 -1.90759706e+00  1.10663664e+00 -1.94096494e+00\n",
      "    3.17280316e+00 -1.19686270e+00  1.50848997e+00 -5.82874358e-01]\n",
      "  [-2.43741536e+00 -1.70882535e+00  1.93996227e+00 -1.41902280e+00\n",
      "    3.15691233e+00 -1.51869428e+00  2.30244160e+00 -9.80429530e-01]\n",
      "  [-2.18082047e+00 -1.66094351e+00  7.46918619e-01 -1.41500652e+00\n",
      "    3.63073444e+00 -1.50028276e+00  2.03664303e+00 -5.13183475e-01]\n",
      "  [ 4.95327520e+00 -1.43041277e+00 -2.56784916e+00 -1.00109732e+00\n",
      "   -3.06406379e-01 -6.88798308e-01  1.47734180e-01  1.66258663e-01]\n",
      "  [-4.11800951e-01 -1.23007989e+00 -7.66572058e-01 -1.21858430e+00\n",
      "    2.35785723e+00 -1.30123043e+00  1.32125676e-01  9.45179403e-01]\n",
      "  [-3.17173243e-01 -1.12656534e+00 -5.27441382e-01 -1.10278201e+00\n",
      "    2.03295898e+00 -1.27387524e+00  2.15990290e-01  8.60142887e-01]\n",
      "  [-7.46671796e-01 -1.70226061e+00 -1.15237856e+00 -1.13715076e+00\n",
      "    4.16151857e+00 -1.24572933e+00  1.80970713e-01 -5.03490642e-02]\n",
      "  [-7.95282125e-01 -1.33761346e+00 -1.18584061e+00 -1.24321330e+00\n",
      "    3.92723966e+00 -1.14807475e+00 -1.65423661e-01  1.02475323e-01]\n",
      "  [-5.72854638e-01 -1.12361407e+00 -9.42320704e-01 -1.27574360e+00\n",
      "    2.91097236e+00 -1.17601955e+00  4.95462567e-02  5.01623631e-01]\n",
      "  [-7.47521043e-01 -1.56074083e+00 -1.64893642e-01 -1.47022116e+00\n",
      "    1.92780042e+00 -1.21004462e+00  9.98936534e-01  4.53304410e-01]\n",
      "  [-1.02165163e+00 -1.86115611e+00 -1.13940346e+00 -1.17952383e+00\n",
      "    4.64497280e+00 -1.13142943e+00  3.07965185e-02 -3.15649137e-02]\n",
      "  [-1.08194983e+00 -1.56182492e+00 -1.41555643e+00 -1.48314810e+00\n",
      "    5.29801655e+00 -1.20706058e+00  9.82621610e-02 -6.12330064e-02]\n",
      "  [-9.81112003e-01 -1.45954871e+00 -1.19142091e+00 -1.44706845e+00\n",
      "    4.76408005e+00 -1.12732339e+00 -8.98841396e-03 -1.60657153e-01]\n",
      "  [-7.28825688e-01 -1.31297302e+00 -1.07547665e+00 -1.26471710e+00\n",
      "    4.53980398e+00 -1.00149703e+00 -1.61169991e-01 -2.34252349e-01]\n",
      "  [-1.18300045e+00 -1.26250231e+00 -1.02660990e+00 -1.30687177e+00\n",
      "    4.48637629e+00 -1.11954498e+00  2.59584635e-01 -1.23511419e-01]\n",
      "  [-7.65687644e-01 -1.23568928e+00 -9.82019603e-01 -1.47468269e+00\n",
      "    3.90378165e+00 -9.51401114e-01  1.57660499e-01  4.84441146e-02]\n",
      "  [-6.58386707e-01 -1.37238657e+00 -9.64130878e-01 -1.52789247e+00\n",
      "    3.70790982e+00 -9.67403650e-01  1.15255080e-01  1.53419927e-01]\n",
      "  [-1.19703996e+00 -1.60779977e+00  4.51157950e-02 -1.45482910e+00\n",
      "    3.77635360e+00 -1.62239504e+00  8.73117983e-01 -7.32755542e-01]\n",
      "  [-1.01274598e+00 -1.55366838e+00 -1.25539804e+00 -1.33082092e+00\n",
      "    4.41658640e+00 -1.27453780e+00 -7.98077136e-02 -2.00339332e-01]\n",
      "  [-6.86112523e-01 -1.24015987e+00 -1.32061398e+00 -1.28557336e+00\n",
      "    3.64995360e+00 -1.15237939e+00 -1.87468752e-01  3.13480496e-01]\n",
      "  [-3.14811140e-01 -1.10860968e+00 -5.81219018e-01 -1.09592152e+00\n",
      "    2.08909488e+00 -1.28629696e+00  1.92170069e-01  8.46525550e-01]\n",
      "  [-3.37321669e-01 -1.09066427e+00 -7.36532331e-01 -1.23179185e+00\n",
      "    2.27892518e+00 -1.32215679e+00  2.19858378e-01  9.85120177e-01]\n",
      "  [-5.45243561e-01 -1.02191448e+00 -1.11031389e+00 -1.28438044e+00\n",
      "    3.25295854e+00 -1.15388155e+00 -1.32939592e-01  2.49461234e-01]\n",
      "  [-5.46161354e-01 -1.03136623e+00 -1.03960276e+00 -1.31650841e+00\n",
      "    3.22293186e+00 -1.13759780e+00 -9.50716510e-02  2.23790407e-01]\n",
      "  [-4.74969804e-01 -1.02134085e+00 -9.36550379e-01 -1.34591234e+00\n",
      "    2.94467139e+00 -1.11910212e+00  4.97295633e-02  3.76466632e-01]\n",
      "  [-1.21108067e+00 -1.98528230e+00 -2.45283589e-01 -1.42826664e+00\n",
      "    3.11758780e+00 -1.41737282e+00  9.86660480e-01  8.41888860e-02]\n",
      "  [-1.02833450e+00 -1.88397026e+00 -1.28998101e+00 -1.22710633e+00\n",
      "    4.86694384e+00 -1.25050521e+00  1.80519745e-01 -9.53018442e-02]\n",
      "  [-1.02940834e+00 -1.57530570e+00 -1.35149598e+00 -1.44398570e+00\n",
      "    5.19242573e+00 -1.21372533e+00  5.28606474e-02 -1.77193463e-01]\n",
      "  [-1.01609576e+00 -1.44044101e+00 -1.20783412e+00 -1.42950857e+00\n",
      "    4.93105078e+00 -1.15233588e+00 -2.89262440e-02 -1.55669242e-01]\n",
      "  [-1.22368872e+00 -1.27331209e+00 -1.11750281e+00 -1.23936617e+00\n",
      "    4.87375116e+00 -1.09437227e+00  1.82261810e-01 -1.78439468e-01]\n",
      "  [-9.75243688e-01 -1.23850155e+00 -9.66301203e-01 -1.41222417e+00\n",
      "    4.10516596e+00 -1.00508535e+00  1.76428169e-01 -4.18082997e-02]\n",
      "  [-7.34302461e-01 -1.24345088e+00 -9.90316808e-01 -1.49265146e+00\n",
      "    3.88678503e+00 -9.47768927e-01  1.36638179e-01  5.81758954e-02]\n",
      "  [-7.65073597e-01 -1.43451405e+00  1.16041392e-01 -1.60451543e+00\n",
      "    2.97906089e+00 -1.33806920e+00  3.13888401e-01 -2.22177684e-01]]]\n",
      "Token:[CLS]\n",
      "Predict_Tag:B_INCLUSION\n",
      "\n",
      "Token:1\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:)\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:Cover\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:##age\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:is\n",
      "Predict_Tag:B_INCLUSION\n",
      "\n",
      "Token:available\n",
      "Predict_Tag:I_INCLUSION\n",
      "\n",
      "Token:for\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:up\n",
      "Predict_Tag:B_INCLUSION\n",
      "\n",
      "Token:to\n",
      "Predict_Tag:I_INCLUSION\n",
      "\n",
      "Token:one\n",
      "Predict_Tag:I_INCLUSION\n",
      "\n",
      "Token:(\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:1\n",
      "Predict_Tag:B_INCLUSION\n",
      "\n",
      "Token:)\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:visit\n",
      "Predict_Tag:B_INCLUSION\n",
      "\n",
      "Token:per\n",
      "Predict_Tag:B_INCLUSION\n",
      "\n",
      "Token:week\n",
      "Predict_Tag:B_INCLUSION\n",
      "\n",
      "Token:for\n",
      "Predict_Tag:I_INCLUSION\n",
      "\n",
      "Token:adult\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:day\n",
      "Predict_Tag:O\n",
      "\n",
      "Token:center\n",
      "Predict_Tag:B_INCLUSION\n",
      "\n",
      "Token:services\n",
      "Predict_Tag:I_INCLUSION\n",
      "\n",
      "Token:.\n",
      "Predict_Tag:I_INCLUSION\n",
      "\n",
      "Token:[SEP]\n",
      "Predict_Tag:B_INCLUSION\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['[CLS]',\n",
       "  '1',\n",
       "  ')',\n",
       "  'Cover',\n",
       "  '##age',\n",
       "  'is',\n",
       "  'available',\n",
       "  'for',\n",
       "  'up',\n",
       "  'to',\n",
       "  'one',\n",
       "  '(',\n",
       "  '1',\n",
       "  ')',\n",
       "  'visit',\n",
       "  'per',\n",
       "  'week',\n",
       "  'for',\n",
       "  'adult',\n",
       "  'day',\n",
       "  'center',\n",
       "  'services',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['B_INCLUSION',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B_INCLUSION',\n",
       "  'I_INCLUSION',\n",
       "  'O',\n",
       "  'B_INCLUSION',\n",
       "  'I_INCLUSION',\n",
       "  'I_INCLUSION',\n",
       "  'O',\n",
       "  'B_INCLUSION',\n",
       "  'O',\n",
       "  'B_INCLUSION',\n",
       "  'B_INCLUSION',\n",
       "  'B_INCLUSION',\n",
       "  'I_INCLUSION',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B_INCLUSION',\n",
       "  'I_INCLUSION',\n",
       "  'I_INCLUSION',\n",
       "  'B_INCLUSION'])"
      ]
     },
     "execution_count": 104,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_iob_predict(\"1) Coverage is available for up to one (1) visit per week for adult day center services.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DfnUFvY-VStQ",
    "outputId": "2c2634f6-0f05-4681-e2db-2753c8ef5cf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '-', 'Laboratory', 'and', 'Radio', '##logy', ':', 'Testing', 'or', 'clinical', 'studies', 'of', 'materials', ',', 'fluids', 'or', 'tissues', 'from', 'patients', ',', 'services', 'include', 'but', 'are', 'not', 'limited', 'to', ',', 'the', 'obtaining', 'and', 'testing', 'of', 'blood', 'samples', ',', 'his', '##tology', ',', 'hem', '##ato', '##logy', ',', 'blood', '[SEP]']\n",
      "['B_INCLUSION', 'O', 'O', 'O', 'O', 'B_INCLUSION', 'I_INCLUSION', 'O', 'B_INCLUSION', 'I_INCLUSION', 'I_INCLUSION', 'O', 'B_INCLUSION', 'O', 'B_INCLUSION', 'B_INCLUSION', 'B_INCLUSION', 'I_INCLUSION', 'O', 'O', 'B_INCLUSION', 'I_INCLUSION', 'I_INCLUSION', 'B_INCLUSION', 'B_INCLUSION', 'O', 'B_INCLUSION', 'B_INCLUSION', 'B_INCLUSION', 'B_INCLUSION', 'B_INCLUSION', 'B_INCLUSION', 'B_INCLUSION', 'B_INCLUSION', 'B_INCLUSION', 'B_INCLUSION', 'B_INCLUSION', 'B_INCLUSION', 'B_INCLUSION', 'B_INCLUSION', 'B_INCLUSION', 'B_INCLUSION', 'B_INCLUSION', 'B_INCLUSION', 'B_INCLUSION']\n",
      "B_INCLUSION\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "B_INCLUSION\n",
      "I_INCLUSION\n",
      "O\n",
      "B_INCLUSION\n",
      "I_INCLUSION\n",
      "I_INCLUSION\n",
      "O\n",
      "B_INCLUSION\n",
      "O\n",
      "B_INCLUSION\n",
      "B_INCLUSION\n",
      "B_INCLUSION\n",
      "I_INCLUSION\n",
      "O\n",
      "O\n",
      "B_INCLUSION\n",
      "I_INCLUSION\n",
      "I_INCLUSION\n",
      "B_INCLUSION\n",
      "B_INCLUSION\n",
      "O\n",
      "B_INCLUSION\n",
      "B_INCLUSION\n",
      "B_INCLUSION\n",
      "B_INCLUSION\n",
      "B_INCLUSION\n",
      "B_INCLUSION\n",
      "B_INCLUSION\n",
      "B_INCLUSION\n",
      "B_INCLUSION\n",
      "B_INCLUSION\n",
      "B_INCLUSION\n",
      "B_INCLUSION\n",
      "B_INCLUSION\n",
      "B_INCLUSION\n",
      "B_INCLUSION\n",
      "B_INCLUSION\n",
      "B_INCLUSION\n",
      "B_INCLUSION\n",
      "B_INCLUSION\n",
      "[',', 'of', '##logy', 'blood', '##logy :', 'his', '##ato', 'and', 'to', 'not', 'testing', 'samples', 'obtaining', 'or clinical studies', 'services include but', 'materials', '##tology', 'the', 'tissues from', 'or', 'hem', 'fluids', 'are']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "words,tags = bert_iob_predict(\" - Laboratory and Radiology:  Testing or clinical studies of materials, fluids or tissues from patients, services include but are not limited to, the obtaining and testing of blood samples, histology, hematology, blood chemistry, pathology, histopathology, microbiology, and other diagnostic testing using physical specimens such as tissue, sputum, feces, urine or blood.\")\n",
    "print(words)\n",
    "print(tags)\n",
    "inclusions = []\n",
    "exclusions = []\n",
    "b_incl_index = []\n",
    "b_excl_index = []\n",
    "final_len = len(tags)\n",
    "\n",
    "for i in range(len(tags)):\n",
    "  print(tags[i])\n",
    "  if tags[i] == \"U_INCLUSION\":\n",
    "    inclusions.append(words[i])\n",
    "  elif tags[i] == \"U_EXCLUSION\":\n",
    "    exclusions.append(words[i])\n",
    "  elif tags[i] == \"B_INCLUSION\":\n",
    "    b_incl_index.append(i)\n",
    "  elif tags[i] == \"B_EXCLUSION\":\n",
    "    b_excl_index.append(i)\n",
    "b_incl_index.append(final_len)\n",
    "b_excl_index.append(final_len)\n",
    "\n",
    "for i in range(len(b_incl_index)-1):\n",
    "  incl_string = \"\"\n",
    "  for j in range(b_incl_index[i],b_incl_index[i+1]):\n",
    "    if tags[j]!=\"O\":\n",
    "      incl_string = incl_string + \" \" + str(words[j])\n",
    "  inclusions.append(incl_string[1:])\n",
    "\n",
    "for i in range(len(b_excl_index)-1):\n",
    "  excl_string = \"\"\n",
    "  for j in range(b_excl_index[i],b_excl_index[i+1]):\n",
    "    if tags[j]!=\"O\":\n",
    "      excl_string = excl_string + \" \" + str(words[j])\n",
    "  exclusions.append(excl_string[1:])\n",
    "\n",
    "inclusions = list(set(inclusions) - set(['[CLS]','[SEP]']))\n",
    "print(inclusions)\n",
    "print(exclusions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "id": "YwYVH4DfcWDL"
   },
   "outputs": [],
   "source": [
    "def prediction_func_bert(req_text):\n",
    "  final_output = []\n",
    "  req_text_df = df_data[df_data[\"requirement_text\"] == req_text]\n",
    "  sentences_df = []\n",
    "  tags_org = []\n",
    "  for i in range(len(req_text_df[\"sentence #\"].unique())):\n",
    "    temp_req_text_df = req_text_df[req_text_df['sentence #'] == req_text_df[\"sentence #\"].unique()[i]]\n",
    "    sentences_df.append(temp_req_text_df[\"pattern\"].iloc[0])\n",
    "    tags_org.append(list(temp_req_text_df[\"tags\"]))\n",
    "\n",
    "  # print(sentences_df)\n",
    "  # print(tags_org)\n",
    "\n",
    "  for sent in range(len(sentences_df)):\n",
    "    words,tags = bert_iob_predict(sentences_df[sent])\n",
    "\n",
    "    #### get inclusions, exclusions\n",
    "    inclusions = []\n",
    "    exclusions = []\n",
    "    b_incl_index = []\n",
    "    b_excl_index = []\n",
    "    final_len = len(tags)\n",
    "\n",
    "    for i in range(len(tags)):\n",
    "      if tags[i] == \"U_INCLUSION\":\n",
    "        inclusions.append(words[i])\n",
    "      elif tags[i] == \"U_EXCLUSION\":\n",
    "        exclusions.append(words[i])\n",
    "      elif tags[i] == \"B_INCLUSION\":\n",
    "        b_incl_index.append(i)\n",
    "      elif tags[i] == \"B_EXCLUSION\":\n",
    "        b_excl_index.append(i)\n",
    "    b_incl_index.append(final_len)\n",
    "    b_excl_index.append(final_len)\n",
    "\n",
    "    for i in range(len(b_incl_index)-1):\n",
    "      incl_string = \"\"\n",
    "      for j in range(b_incl_index[i],b_incl_index[i+1]):\n",
    "        if tags[j]!=\"O\":\n",
    "          incl_string = incl_string + \" \" + str(words[j])\n",
    "      inclusions.append(incl_string[1:])\n",
    "\n",
    "    for i in range(len(b_excl_index)-1):\n",
    "      excl_string = \"\"\n",
    "      for j in range(b_excl_index[i],b_excl_index[i+1]):\n",
    "        if tags[j]!=\"O\":\n",
    "          excl_string = excl_string + \" \" + str(words[j])\n",
    "      exclusions.append(excl_string[1:])\n",
    "\n",
    "    inclusions = list(set(inclusions) - set(['[CLS]','[SEP]']))\n",
    "    # print(inclusions)\n",
    "    # print(exclusions)\n",
    "\n",
    "    ###### get accuracy and f1\n",
    "\n",
    "    tags_pred = tags\n",
    "    tags_old = tags_org[sent]\n",
    "    if len(tags_pred) < len(tags_old):\n",
    "      diff = len(tags_old)-len(tags_pred)\n",
    "      for i in range(diff):\n",
    "        tags_pred.append('O')\n",
    "    if len(tags_old) < len(tags_pred):\n",
    "      diff = len(tags_pred)-len(tags_old)\n",
    "      for i in range(diff):\n",
    "        tags_old.append('O')\n",
    "\n",
    "    # print(\"accuracy score: %f\"%(accuracy_score(tags_pred, tags_old)))\n",
    "    # print(\"f1 score: %f\"%(f1_score([tags_pred], [tags_old])))\n",
    "\n",
    "    temp_pred_json = {}\n",
    "    temp_pred_json[\"Inclusions\"] = \",\".join(inclusions)\n",
    "    temp_pred_json[\"Exclusions\"] = \",\".join(exclusions)\n",
    "    temp_pred_json[\"Accuracy score\"] = accuracy_score(tags_pred, tags_old)\n",
    "    temp_pred_json[\"f1 score\"] = f1_score([tags_pred], [tags_old])\n",
    "    # print(temp_pred_json)\n",
    "    final_output.append(temp_pred_json)\n",
    "  print(final_output)\n",
    "  return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y5w3azVwbFM5",
    "outputId": "90f3d05f-da89-4b48-c47e-838c362160da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Inclusions': \"condition,',nutrition,a supervised,pressure,factor,blood,;,includes counseling,information about the,and,on,information,high,such,controlling,smoking,risk,##ess,programs,; lifestyle and,as,##ation,c,,\", 'Exclusions': '', 'Accuracy score': 0.28888888888888886, 'f1 score': 0.0}, {'Inclusions': 'services,of,rehabilitation,-,cardiac,each,factor,;,and,day,##an,furnished,Card,intensive cardiac rehabilitation,modification,the following,risk,Ph ##ys ##ici,all,must,exercise,##iac,rehabilitation programs,items,,,are', 'Exclusions': '', 'Accuracy score': 0.2222222222222222, 'f1 score': 0.0}, {'Inclusions': 'cardiac,programs,not qualify for,.,heart failure', 'Exclusions': '', 'Accuracy score': 0.17647058823529413, 'f1 score': 0.0}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_INCLUSION seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_INCLUSION seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_EXCLUSION seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_EXCLUSION seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'Accuracy score': 0.28888888888888886,\n",
       "  'Exclusions': '',\n",
       "  'Inclusions': \"condition,',nutrition,a supervised,pressure,factor,blood,;,includes counseling,information about the,and,on,information,high,such,controlling,smoking,risk,##ess,programs,; lifestyle and,as,##ation,c,,\",\n",
       "  'f1 score': 0.0},\n",
       " {'Accuracy score': 0.2222222222222222,\n",
       "  'Exclusions': '',\n",
       "  'Inclusions': 'services,of,rehabilitation,-,cardiac,each,factor,;,and,day,##an,furnished,Card,intensive cardiac rehabilitation,modification,the following,risk,Ph ##ys ##ici,all,must,exercise,##iac,rehabilitation programs,items,,,are',\n",
       "  'f1 score': 0.0},\n",
       " {'Accuracy score': 0.17647058823529413,\n",
       "  'Exclusions': '',\n",
       "  'Inclusions': 'cardiac,programs,not qualify for,.,heart failure',\n",
       "  'f1 score': 0.0}]"
      ]
     },
     "execution_count": 242,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_func_bert('Cardiac Rehabilitation Services')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4leEtyag53BI"
   },
   "outputs": [],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 709
    },
    "id": "460auY0D5rAa",
    "outputId": "c7a54dc5-7a4f-4c87-972c-64a032e1b7ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\n",
      "This share link will expire in 24 hours. If you need a permanent link, visit: https://gradio.app/introducing-hosted (NEW!)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:paramiko.transport:Connected (version 2.0, client OpenSSH_7.6p1)\n",
      "INFO:paramiko.transport:Authentication (publickey) successful!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on External URL: https://53930.gradio.app\n",
      "Interface loading below...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"500\"\n",
       "            src=\"https://53930.gradio.app\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fea78044ed0>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tip: Add interpretation to your model by simply adding `interpretation=\"default\"` to `Interface()`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<Flask 'gradio.networking'>,\n",
       " 'http://127.0.0.1:7861/',\n",
       " 'https://53930.gradio.app')"
      ]
     },
     "execution_count": 243,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "benefit_iface = gr.Interface(fn=prediction_func_bert, inputs=gr.inputs.Textbox(default=\"Please enter the Benefit Text.\"), outputs=\"json\")\n",
    "benefit_iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OfSb299K6EPt"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Medicare_BERT_Inc_Exc_Analysis_v4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0228fc0583444636bf2bc92f83f53cb4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_672b6fc956fd481caa70d824c2bc1497",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_41d4afcf02a644daa22edb88c4ecc3f8",
      "value": 570
     }
    },
    "258046856ac54a46beda80683cdd24f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2c36f5eccd884e18bea9d54eef560256",
       "IPY_MODEL_a8455efbba974124b6ba057aff68ed01"
      ],
      "layout": "IPY_MODEL_d2f923f4f1984e4fbce147a7c7ed4429"
     }
    },
    "2c36f5eccd884e18bea9d54eef560256": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6052d62cf1144acca8dcaba39ca5295d",
      "max": 435779157,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_31bfdc18004d4614a819e122227db0e5",
      "value": 435779157
     }
    },
    "2effd0bbb9a8458f827845e59030075e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31bfdc18004d4614a819e122227db0e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "38427f3a385745fc83f6213e959e911a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41d4afcf02a644daa22edb88c4ecc3f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "4a8e68ea8ead4fae86d7b8624fb95d65": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6052d62cf1144acca8dcaba39ca5295d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "672b6fc956fd481caa70d824c2bc1497": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84f79d21a6ac4dcfaf6e31b7c5951e33": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "910e0b344a7e4a8982959d9ae791a5fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_38427f3a385745fc83f6213e959e911a",
      "placeholder": "​",
      "style": "IPY_MODEL_84f79d21a6ac4dcfaf6e31b7c5951e33",
      "value": " 570/570 [00:00&lt;00:00, 2.78kB/s]"
     }
    },
    "a8455efbba974124b6ba057aff68ed01": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2effd0bbb9a8458f827845e59030075e",
      "placeholder": "​",
      "style": "IPY_MODEL_4a8e68ea8ead4fae86d7b8624fb95d65",
      "value": " 436M/436M [00:10&lt;00:00, 40.6MB/s]"
     }
    },
    "b42042e06e734c93ae091bc6a3720804": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cbb8c7bf7899439e9ced554912334527": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0228fc0583444636bf2bc92f83f53cb4",
       "IPY_MODEL_910e0b344a7e4a8982959d9ae791a5fb"
      ],
      "layout": "IPY_MODEL_b42042e06e734c93ae091bc6a3720804"
     }
    },
    "d2f923f4f1984e4fbce147a7c7ed4429": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
